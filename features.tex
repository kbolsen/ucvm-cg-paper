
\section{Features}
\label{sec:features}

The UCVM platform offers an API and a set of programs, many of which can be used either in a single processor context or in parallel. This section details the most relevant of these programs, categorized by the broad feature they are intended to support. The discussion will focus largely on how the single processor programs operate. Those features that have additional support for parallel computing will be noted, and any operational differences between the single core and parallel implementations are also described.

The single-core commands can be run in any system where the platform has been successfully installed. The parallel commands, however, require a system where the standard Message Passing Interface (MPI) library and compilers are available. Single-core commands are useful to most users interested in exploring the properties of the regions covered by the models supported by the platform. On the other hand, advanced users needing to build large-scale (regional) materialized velocity models for earthquake modeling and simulation are the more likely to use the MPI commands. 

\input{figure-tiling}

\subsection{Querying Material Properties}
\label{sec:querying}

UCVM provides two methods for querying models. The first method is programmatically, directly through the provided C language API. The second is via the command-line program \texttt{ucvm\_query}. Both methods query the underlying models in the same manner; the \texttt{ucvm\_query} program is merely a simplified front-end layered upon the API.

The query process begins with the identification of one or more CVMs as the source of material properties. In this respect, the framework distinguishes between geotechnical layers and standard crustal models, allowing the user to make selections for both. As illustrated in Figure \ref{fig:tiling}, the set of standard crustal models is tiled in three dimensions to form a meta-model. The same operation is performed on the GTLs to define a meta-GTL. The interface between the meta-GTL and meta-model is then smoothed using an interpolation function (linear interpolation in the simplest case) along a user-defined interpolation zone parallel to the z-axis. Note that when two or more models overlap in three dimensional space, the model listed first within the tiling order will satisfy requests within that overlapping zone.

Once the models have been tiled in this manner, the API or program accepts one or more input query points from the user. For every point, the framework queries each component model of the two meta models, until either a valid set of velocities and density are returned, or all component models have been queried and the request was unsatisfied. Thus, for points that fall within the interpolation zone, two sets of material properties may be generated---one for each meta model. These two sets of material properties are then combined using the interpolation function. As the native query interfaces of available CVMs accept query points in a wide array of formats (e.g., geographic coordinates versus UTM-11 map coordinates, or depth versus elevation for the vertical component), UCVM may perform a coordinate transformation to convert its input format of decimal (latitude, longitude, depth/elevation) tuples to the local coordinate system of the component model being queried. This is accomplished transparently by utilizing the standard projection library Proj.4 \citep{Evenden_2003_Manual}.

In the case of the API, the result of a successful query is a data-structure containing the velocities \vp{} and \vs{}, and the density $\rho$ at the point of interest, along with the elevation in meters and $V_{S30}$ value of the corresponding point on the free-surface. This data-structure also includes an indicator of which velocity model within the meta-model ultimately satisfied the request. For those points which fall within the interpolation zone between the meta-GTL and meta-model, the framework additionally identifies the material properties reported by the meta-GTL and the meta-model, as well as the component models from which they were extracted. For the \texttt{ucvm\_query} program, this same information is formulated in tabular format and printed to the screen.

This tiling mechanism mostly allows one to complement missing information in one model with that of other overlapping or underlying models. In the future, the UCVM tiling feature could be used as tool for combining multiple regional velocity models. The platform, however, does not presently provide built-in functionalities to do so beyond the described tiling mechanism. The reason being that consistency problems arise when velocity models overlap in three-dimensional space. That is, tiling two overlapping models that are not compatible has the potential of creating interfaces with unnatural contrasts. These artifacts are undesirable for earthquake simulation applications because they can cause unexpected wave reflections or refractions. There are two approaches one can think of to remedy this problem. The simplest approach is to define a UCVM patch model to trilinearly interpolate the material properties within a certain geographic region. This patch model may be tiled along with the overlapping traditional velocity models to produce a smoothed meta-model. However, this numerical smoothing approach does may reflect the physical structures of the Earth's surface. The second approach is to utilize UCVM to query all models within the overlap zone individually, and then manually combine the results with a user-defined interpolation function. We expect that future tomographic inversions of larger regions will allow us to integrate better models or algorithms to handle this.

\input{figure-meshing}

\subsection{Creating Structured 3D Meshes}

One of the most important features of UCVM is that the framework can be used to generate uniform grids (here also referred as structured meshes) in a format consistent with that used by the AWP-ODC simulation code \citep{Cui_2010_Proc}. This feature is supported through the program \texttt{ucvm2mesh}.

Construction of a mesh proceeds as shown in Figure \ref{fig:meshing}. The user specifies a two-dimensional map projection (such as UTM-11), a latitude and longitude geographic anchor point, mesh cell dimensions ($n_x$, $n_y$, $n_z$) along the $x$, $y$ and $z$ axis (where the $x,y$ coordinates define the plane of the projection and $z$ is the vertical component), step size $d_x$ in meters within the projected space, and rotation angle within the map projection. Additionally, the user provides a list of CVMs to query. These models are then tiled by the program as described above.

The program \texttt{ucvm2mesh} projects the geographic coordinates of the Earth's surface into the map projection, placing the origin of the mesh as the anchor point and discretizing the volume according to the provided dimensions and step size. For each point in the projected volume, \texttt{ucvm2mesh} determines the analogous geographic point in terms of latitude, longitude and depth, and queries the underlying CVMs for material properties. These material properties are then assigned to the mesh point. In the process, a minimum \vs{} floor can also be set to bound lower velocities.

The output of the program is a binary file consisting of a list of $n_xn_yn_z$ tuples. Each tuple contains three single precision floating point values (\vp{}, \vs{}, $\rho$), representing the material properties for a point in the mesh, with the mesh coordinates given implicitly by the position of the tuple in the list. The tuples are arranged in $x$-$y$-$z$ order, with units of m/s for the velocities and kg/m$^3$ for the density.

To facilitate the construction of very large meshes, the framework also offers a parallel version of the mesher named \texttt{ucvm2mesh-mpi}. This MPI program operates analogously to that of the serial version (see Figure \ref{fig:meshing}). Spatial decomposition is performed by mapping subblocks of the meshing region to individual processors for extraction. The mapping is specified by providing a processor grid to the program at startup, which specifies the number of processors along each dimension. If the meshing region is sized $(n_x \times n_y \times n_z)$ grid points along each dimension, and the processor grid is specified as ($p_x$, $p_y$, $p_z$), then each processor is assigned $(n_x/p_x \times n_y/p_y \times n_z/p_z)$ grid points. The only constraint in the mapping is that the processor count along a particular dimension must divide evenly into the number of grid points along that dimension. Once the region has been decomposed in this manner, extraction of material properties is an embarrassingly parallel operation.  

\input{figure-etrees}

\subsection{Creating Etree Databases}

The framework may also be utilized to generate a semi-unstructured octree in the Etree database format \citep{Tu_2003_Tech} using the command-line program \texttt{ucvm2etree}. Two Etree database formats are supported: the Hercules format, and the SCEC format. These two formats differ in the format of their metadata signatures, and more important, in the map projection used to discretize the domain. The Hercules format utilizes a projection that corresponds to a bilinear interpolation based on the four corner coordinates that define the surface bounding box in geographical coordinates. The SCEC format, on the other hand, supports any map projection available in the Proj.4 projection library.

The construction of an Etree proceeds as shown in Figure \ref{fig:etrees}, which follows some of the basic ideas first proposed in the implementation by \citet{Taborda_2007_Proc}. The user specifies the extents of the Etree by describing the $x$-$y$-$z$ dimensions of the domain in meters, as well as providing the geographical data necessary to define a bounding box on the Earth's surface. In the case of the Hercules format this consists of the coordinates of the bounding box on the Earth's surface. In the case of the SCEC format, this is done similarly as in the case of the structured meshes explained before. Using the correspoinding bilinear or Proj.4 projection, this surface bounding box is mapped to the $x$-$y$ plane of the domain. The $z$ dimension of the domain is interpreted as depth from the free surface. In this way, any ($x,y,z$) coordinate in the domain may be transformed to a (\textit{latitude},\textit{longitude},\textit{depth}) coordinate relative to the Earth's surface. It is assumed that the user has pre-computed the domain dimensions such that they reflect the actual distances in the geographic bounding box (using any preferred projection or spheroid model). Note, however, that the octree format places restrictions on the possible valid domain sizes \citep{Tu_2003_Tech, Taborda_2007_Proc}.

% *****

% I changed the above paragraph somewhat considerably, so I am keeping a copy of the old version here at least during one git submission

%For the purposes of this discussion, we shall describe the generation of a Hercules-format Etree database based on \citet{Taborda_2007_Proc}. Construction of such an Etree proceeds as shown in Figure \ref{fig:etrees}. The user specifies the extents of the Etree by describing the x-y-z dimensions of the domain in meters, as well as providing the geographical coordinates of a bounding box on the Earth's surface. This surface bounding box is mapped to the x-y plane of the domain using bilinear interpolation. The z dimension of the domain is interpreted as depth from the free surface. In this way, any $(x,y,z)$ coordinate in the domain may be transformed to a $(latitude, longitude, depth)$ coordinate relative to the Earth's surface. It is assumed that the user has pre-computed the domain dimensions such that they reflect the actual distances in the geographic bounding box (using any preferred projection or spheroid model). Note, however, that the octree format places restrictions on the possible valid domain sizes \citep{Tu_2003_Tech, Taborda_2007_Proc}.

% *****

This domain is then spatially decomposed at a coarse-grained level, dividing the volume into a two-dimensional logical grid of rectangular cuboids (columns) aligned with the $x$-$y$ plane of the original domain, with each column having a fixed size. This decomposition assists in parallelization since the material properties for a particular column can be extracted independently from the others. The number of columns in this logical grid is selectable by the user, subject to two constraints to preserve the octree format. First, the length and width of the columns must be equal. Second, the number of columns along the $x$ and $y$ axis must be a power of two.

With this coarse decomposition complete, each column of the original domain may then be processed in sequence by \texttt{ucvm2etree}, or in parallel, as is the case with the MPI version of this utility (see Figure \ref{fig:etrees}). To extract the material properties for a column, the program further decomposes the column into a collection of octants, maps the center ($x$,$y$,$z$) coordinate of each octant to its corresponding geographic coordinates, and then queries the user-provided list of velocity models to determine the (\vp{},\vs{},$\rho$) payload for each octant. The octants are processed in a top-down fashion, starting at the surface and ending at the maximum depth of the domain. Filled octants are inserted into the Etree database via the Etree API. Note that as opposed to the structured grids explained above, where the query-point and the grid-point have a 1-to-1 mapping relationship, here it is the volume contained by an octant the one who takes the query-point payload properties.

This fine-grain decomposition into octants is an adaptive process that depends on the shear-wave velocities (\vs{}) encountered within that column as well as four parameters provided by the user: \vsmin{}, a floor \vs{} for purposes of bounding octant sizes to a minimum size; \fmax{}, the maximum simulation frequency to support; $p$, the desired number of points per wavelength to be used in a simulation model; and $s_{_{\max}}$, the maximum octant size to allow. Based on these parameters, the program determines the range of octant sizes to allow within a column. The upper bound is determined by:
%
\begin{equation}
\label{eq:octant_upper}
	s_{_{\mathrm{upper}}} = \min ( l_c, s_{_{\max}} )
	\hspace{0.3em},
\end{equation}
%
where $l_c$ is the column length. The lower bound is given by:
%
\begin{equation}
\label{eq:octant_lower}
	s_{_{\mathrm{lower}}} = \frac{ V_{\mathrm{S}_{\min}} }{ p f_{_{\max}}}
	\hspace{0.3em}.
\end{equation}
%
As the octree format places constraints on valid octant sizes, these two bounds are normalized with the relation:
%
\begin{equation}
\label{eq:octant_size}
	s_{_{\mathrm{octant}}} = \frac{ l_d }{ 2^{ \left( \left\lceil \log_{2} \left( \frac{l_d}{s} \right) \right\rceil \right)} }
	\hspace{0.3em}.
\end{equation}
%
Here, the variable $l_d$ is the domain length (longest side); and the variable $s$ is the size to normalize, which is either $s_{_{\mathrm{upper}}}$ or $s_{_{\mathrm{lower}}}$, corresponding to the upper and lower bounds, respectively.

With these bounds established, the program successively queries two-dimensional slices of octants, starting at the column surface and stepping downward to greater depths. Initially, the octants are of size $s_{_{\mathrm{lower}}}$ (maximum resolution). Then, as the program progresses downwards, the octants are resized based on the actual \vs{} values encountered within a slice. After each slice is queried, the minimum \vs{} found within is inserted into equation (\ref{eq:octant_lower}) and then normalized with (\ref{eq:octant_size}) to yield an updated octant size. If this new size differs from the current size while still falling within the $s_{_{\mathrm{lower}}}$ and $s_{_{\mathrm{upper}}}$ bounds, and if this size fits in the remaining vacant space of the octree, then the slice is re-queried at the new size. Otherwise, the slice of octants is accepted as queried and inserted into the Etree database.

This adaptive refinement continues as the program steps down through the column. As \vs{} values typically increase with depth, the program will tend to select larger octant-sizes as it proceeds deeper into the column (as illustrated int eh column shown in Figure \ref{fig:etrees}, to the left). This refinement algorithm ensures that each column is extracted at a resolution which supports the maximum simulation frequency, while at the same time allowing for considerable space savings at depth. Since the column properties are defined by the user, but the meshing of each column is adaptive, we defined the output of this process as a semi-unstructured mesh.

The MPI implementation of \texttt{ucvm2etree} consists of a workflow with three programs: \texttt{ucvm2etree\_extract}, \texttt{ucvm2etree\_sort}, and \texttt{ucvm2etree\_merge}. The program \texttt{ucvm2etree\_extract} performs the same spatial decomposition and velocity model querying as described above, with the change that each column is extracted independently by each processor and the octants are temporarily saved to disk in flat binary files. The program \texttt{ucvm2etree\_sort} locally sorts the octants of each column by their location code. The last program in the workflow, \texttt{ucvm2etree\_merge}, performs a merge sort of the locally sorted columns, such that rank 0 inserts the ordered octants one at a time into the Etree database \citep[in its natural $z$-order; see][]{Tu_2003_Tech}. Since the octants are globally sorted at this point, the insertion is simply an append operation. 

This scheme, while more complicated than the sequential program, allows extraction to occur in parallel while \texttt{ucvm2etree\_merge} utilizes the most efficent insertion method provided by the Etree library (\texttt{etree\_append}), which operates in $z$-order. By contrast, when running the sequential program, storage of the payload into the Etree is handled with the library function \texttt{etree\_insert}, in the order queries to the meta-model are done. This is not the same order as that of the Etree. As a result, the binary file contains ``unused'' disk space. The resulting Etree can be optimized by running the program \texttt{ecompact}, which traverses an input Etree and creates a copy in the correct compacted order (see Figure \ref{fig:etrees}). Further size optimization can be achieved on any Etree by running the program \texttt{ecoalesce}, which combines octants with identical properties into larger units, thus breaking the initial sub-structure and optimizing disk-space to create truly unstructured models. Both \texttt{ecompact} and \texttt{ecoalesce} were developed as part of an effort independent of the UCVM platform development \citep{Schlosser_2008_Proc}, which inspired some of the ideas used in the UCVM Etree features.

\subsection{Miscellaneous Features}

The UCVM framework encompasses a set of minor features intended to support typical use cases, as well as to enhance ease-of-use. These miscellaneous features are described in greater detail in the following sections.

\subsubsection{Querying $V_s$ Iso-surfaces}

The basin structure of a velocity model may be extracted using the \texttt{basin\_query} command. This program accepts a shear wave velocity threshold $V_{thresh}$, a step interval $d_z$ along the vertical axis, one or more velocity models, and a list of (latitude, longitude) geographic coordinates. The program begins by tiling the velocity models to form the meta-model. Then, for each input coordinate, the meta-model is queried at a sequence of depths, starting at the surface and proceeding downward with step size $d_z$ meters until either the configured $V_{thresh}$ is exceeded or a maximum search depth is reached. The shallowest depth at which this transition occurs, or the maximum depth if no transition was found, is reported to the user. An MPI version of this command, \texttt{basin\_query\_mpi}, is provided to quickly generate maps for large sets of coordinates.

\subsubsection{Visualization}

The framework provdes a simple mechanism for visualizing slices and iso-surfaces from any configured velocity model, based on the scripting language Python and the Python modules \texttt{matplotlib} (with the basemap toolkit) \citep{Hunter_2007_CSE}, \texttt{numpy} %(\url{http://www.numpy.org})
, and \texttt{pyproj} %(\url{https://code.google.com/p/pyproj})
. These Python scripts function as wrappers to the basic single-core commands explained previously.

Plots of horizontal and vertical slices may be generated with the \texttt{horizontal\_slice.py} and \texttt{cross\_section.py} scripts, respectively. Horizontal slices are oriented by a simple bounding box specified in geographic coordinates at a specified depth. Cross sections are oriented by two geographic endpoints and a depth range. In both cases, the slice region is discretized into a grid and each grid point is queried from the velocity model(s). The value plotted may be any one of the three material properties $V_p$, $V_s$, and $\rho$, or the Poisson ratio, $\nu$, of the velocities, given by:
\begin{equation}
\nu = \frac{V_p}{V_S}
\end{equation}
In addition, basin maps for $V_s = 1000$ m/s and $V_s = 2500$ m/s may be plotted using the \texttt{z10.py} and \texttt{z25.py} scripts, respectively. These operate analogously to the \texttt{basin\_query} command described previously. Lastly, generation of $V_{s30}$ maps is supported with the \texttt{vs30.py} script. In all cases, the output images are saved to disk in Portable Network Graphics (PNG) format.

\subsubsection{Small-scale Heterogeneities}

The last decade has seem a tremendous growth in high performance computing applications dedicated to earthquake ground motion simulations, with the goal of performing deterministic simulations at high frequencies of engineering interest (\fmax{} 0--10 Hz). With increasing simulation frequencies, seismic velocity models must not only be accurate representations of a region's crustal structure at the geologic scale and represent the geotechnical characteristics of basins and deposits, but should also provide for the adequate representation of the scattering characteristics of the typical heterogeneities observed in geomaterials. To this end, UCVM provides a mechanism for incorporating small-scale heterogeneities into any underlying velocity model. This mechanism is implemented as a post-processing step to meshing, such that a structured mesh of material properties is first produced using \texttt{ucvm2mesh} and this mesh is subsequently modified to incorporate the small-scale heterogeneities.

Introduction of small-scale heterogeneities begins by constructing an identically sized mesh using the command \texttt{ssh\_generate} (NOTE: cite Olsen). However, the payload of the grid points in this mesh are the perturbations (with a normalized amplitude) to apply to each of the three material properties $V_p$, $V_s$, and $\rho$ of the original mesh. Then, the command \texttt{ssh\_merge} is used to iterate through the cells of the two meshes and add the heterogeneities multiplied by a user-defined scaling factor to the model. The velocities and density of the original mesh are adjusted according to the following relations:
\begin{equation}
\begin{split}
V' &= \frac{V}{(1+k\epsilon)}\\
\rho' &= \frac{\rho}{(1+k\epsilon)}
\end{split}
\end{equation}
Where $k$ is the scaling factor (Note: needs explanation), $\epsilon$ is the perturbation (Note: needs explanation), and $V$ is either of the original velocities $V_s$ or $V_p$.

\textcolor{blue}{DG: For $V_p$ and $V_s$:}

\textcolor{blue}{$V_p$ = 1.0 / ((1 + (scaling factor * perturbation)) * slowness of $V_p$)}

\textcolor{blue}{$V_s$ = 1.0 / ((1 + (scaling factor * perturbation)) * slowness of $V_s$)}

\textcolor{blue}{For $\rho$:}

\textcolor{blue}{$\rho$ = (1 + (scaling factor * perturbation)) * $\rho$}

Note that introduction of the heterogeneities is accomplished by applying the scaled perturbation to the slowness of the underlying mesh velocities, and then converted back to the seismic velocity. 

\subsubsection{Easy Install Utility}
\label{sec:easy.install}

\textcolor{blue}{DG: UCVM includes a Python installation script, \texttt{ucvm\_setup.py}, that will install and configure the software automatically. This script works by querying the SCEC server to download a list of tested machine configurations. Example configurations include supercomputers, such as NCSA Blue Waters, as well as various distributions of Linux and Mac OS X. The UCVM setup script then compares the user's computer to these known configurations. If a match is found, the script then checks that the proper compilers are available and all the software dependecies are met. For example, on NCSA Blue Waters, it ensures that the user has the GNU compilers selected instead of the Cray ones. If the user's computer is not identified, UCVM has basic dependencies for which it checks.}

\textcolor{blue}{Once all dependencies have been satisfied, the script then asks the user to which folder they would like to install UCVM and also which models they would like to download. All libraries and models have been standardized so that they can be downloaded in the same manner. First the file is downloaded, extracted, then a standard Linux "./configure, make, make install" sequence is run. The easy install utility ensures that the directory structure for UCVM is self contained. All library files are installed in "base UCVM directory/lib" and all models in "base UCVM directory/model".}

\textcolor{blue}{Finally, the setup script compiles the UCVM source code with all the libraries and models that the user selected to be installed. The entire process is fully automated from start to finish. If an error is encountered, it notifies the user and also provides them with an e-mail address at SCEC to contact for further assistance.}

